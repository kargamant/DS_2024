{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4ja2M-PsklS"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "import numpy as np\n",
        "\n",
        "def verify(res, b, a):\n",
        "    return not False in [i for i in res==np.dot(b,a)]\n",
        "\n",
        "def matrix_vector_multiply(matrix, vector, shape):\n",
        "    result=np.empty_like(vector)\n",
        "    for i in range(len(vector)):\n",
        "        result[i]=0\n",
        "        for j in range(shape[0]):\n",
        "            result[i]+=matrix[i][j]*vector[j]\n",
        "            #print(result)\n",
        "    return result\n",
        "\n",
        "@cuda.jit\n",
        "def matrix_vector_multiply_parallel(matrix, vector, shape, out):\n",
        "    th_idx = cuda.grid(1)\n",
        "    for i in range(shape[0]):\n",
        "        cuda.atomic.add(out, i, matrix[i][th_idx] * vector[th_idx])\n",
        "\n",
        "@cuda.jit\n",
        "def matrix_vector_multiply_parallel_stride(matrix, vector, shape, stride, out):\n",
        "    th_idx = cuda.grid(1)\n",
        "    for i in range(shape[0]):\n",
        "      for j in range(stride*th_idx, stride*th_idx+stride):\n",
        "        cuda.atomic.add(out, i, matrix[i][j] * vector[j])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def gen_int_matr(shape, start, end):\n",
        "    b=np.empty(shape, dtype=np.int16)\n",
        "    for i in range(shape[1]):\n",
        "        for j in range(shape[0]):\n",
        "            b[i][j]=random.randint(start, end)\n",
        "    return b\n",
        "\n",
        "def gen_float_matr(shape, start, end):\n",
        "    b=np.empty(shape, dtype=np.float16)\n",
        "    for i in range(shape[1]):\n",
        "        for j in range(shape[0]):\n",
        "            b[i][j]=random.uniform(start, end)\n",
        "    return b"
      ],
      "metadata": {
        "id": "kOXWp4IGs1jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape=(16, 16)\n",
        "\n",
        "#vector\n",
        "a=np.arange(0, shape[0]).astype(np.int32)"
      ],
      "metadata": {
        "id": "v6EnD7HguS0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing cpu version\n",
        "results=[]\n",
        "for _ in range(0, 10000):\n",
        "    b=gen_int_matr(shape, 0, 500)\n",
        "    res = matrix_vector_multiply(b, a, shape)\n",
        "    results.append(verify(res, b, a))\n",
        "    if results[-1]==False:\n",
        "        print(\"b:\\n\", b)\n",
        "        print(\"a:\\n\", a)\n",
        "        print(\"res:\\n\", res)\n",
        "        print(\"dot: \\n\", np.dot(b, a))\n",
        "print(\"testing results: \", results.count(True), \" out of \", len(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5GSwckQtH-U",
        "outputId": "0eb9aff0-fab3-4cfc-b9b6-a4793ae99d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing results:  10000  out of  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing gpu version\n",
        "gpu_config = (4, 4)\n",
        "results = []\n",
        "\n",
        "for _ in range(0, 10000):\n",
        "  b = gen_int_matr(shape, 0, 500)\n",
        "  result = np.zeros(shape[0]).astype(np.int32)\n",
        "  b_gpu = cuda.to_device(b)\n",
        "  a_gpu = cuda.to_device(a)\n",
        "  matrix_vector_multiply_parallel[gpu_config](b_gpu, a_gpu, shape, result)\n",
        "  results.append(verify(result, b, a))\n",
        "print(\"testing results: \", results.count(True), \" out of \", len(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4dApk6OuYjD",
        "outputId": "a49ac2eb-c4d1-4859-fd42-601ed0a147a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing results:  10000  out of  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# big test\n",
        "shape = (4096, 4096)\n",
        "\n",
        "a = np.arange(0, shape[0]).astype(np.int32)\n",
        "b = gen_int_matr(shape, 0, 500)"
      ],
      "metadata": {
        "id": "X5gX7GuLtM-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_gpu = cuda.to_device(a)\n",
        "b_gpu = cuda.to_device(b)\n",
        "gpu_config = (64, 64)\n",
        "out = np.zeros(shape[0]).astype(np.int32)"
      ],
      "metadata": {
        "id": "qPLEFVNRCgP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit matrix_vector_multiply_parallel[gpu_config](b_gpu, a_gpu, shape, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxcCz84YBlpn",
        "outputId": "11f0f4e7-33b4-443a-c467-aecf7bece51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.28 ms ± 42.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit matrix_vector_multiply(b, a, shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_aPUiXLEZNW",
        "outputId": "6ee49fa3-406f-4ef1-b5ee-ac099e517a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-8dd1e2bbc7e5>:12: RuntimeWarning: overflow encountered in scalar add\n",
            "  result[i]+=matrix[i][j]*vector[j]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.8 s ± 306 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_gpu = cuda.to_device(a)\n",
        "b_gpu = cuda.to_device(b)\n",
        "stride = 2\n",
        "gpu_config = (64, 32)\n",
        "out = np.zeros(shape[0]).astype(np.int32)"
      ],
      "metadata": {
        "id": "cIeCfSlfd8Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit matrix_vector_multiply_parallel_stride[gpu_config](b_gpu, a_gpu, shape, stride, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsjl5HSAfRow",
        "outputId": "0a269902-cef0-4945-dd5d-8fe88664580a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.24 ms ± 19.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    }
  ]
}